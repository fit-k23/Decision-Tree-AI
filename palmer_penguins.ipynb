{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7064476cc7465eb",
   "metadata": {},
   "source": [
    "# 1.1 Install scikit-learn & required library\n",
    "This project require numpy, pandas, matplotlib,... and scikit-learn be installed. Run the following code to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca31cc932f8ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U scikit-learn\n",
    "!python -m pip show scikit-learn\n",
    "!python -c \"import sklearn; sklearn.show_versions()\"\n",
    "!python -m pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94897b32718917d7",
   "metadata": {},
   "source": [
    "# 1.2 Preparing the datasets\n",
    "The following code will the dataset palmerpenguins from URL.\n",
    "\n",
    "â€¢ Multi-class dataset: The [Palmer Penguins dataset](https://archive.ics.uci.edu/dataset/690/palmer+penguins-3) is used for classifying penguin species\n",
    "based on physical characteristics. The dataset includes 344 samples of three penguin species:\n",
    "Adelie, Chinstrap, and Gentoo, with features such as bill length, flipper length, body mass,\n",
    "and sex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d808ded277c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"palmerpenguins\"\n",
    "palmerpenguins_db_url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/refs/heads/main/inst/extdata/penguins.csv\"\n",
    "\n",
    "def split_dataset(dataset: pd.DataFrame, targets: list):\n",
    "    existing_columns = [col for col in targets if col in dataset.columns]\n",
    "    missing_columns = [col for col in targets if col not in dataset.columns]\n",
    "    if missing_columns:\n",
    "\t    print(\"These columns are not found in the dataset:\", missing_columns)\n",
    "    return {\n",
    "\t\t\"feature\": dataset.drop(existing_columns, axis=1),\n",
    "\t\t\"target\": dataset[existing_columns],\n",
    "    }\n",
    "\n",
    "# fetch dataset from url\n",
    "dataset = split_dataset(pd.read_csv(palmerpenguins_db_url).drop(['island', 'year', 'bill_depth_mm'], axis=1), targets=['species']) # excluding unrelated data\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13822b547f6a99b3",
   "metadata": {},
   "source": [
    "# 1.3 Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1be8d2f23783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_dataset(features, labels, test_size=0.2):\n",
    "\t\"\"\"\n",
    "\t:param test_size: Test size ratio (test/(train+test))\n",
    "\t:return: feature_train, feature_test, label_train, label_test\n",
    "\t\"\"\"\n",
    "\treturn train_test_split(features, labels, test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c60122f6864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate a dataset with 1000 samples and 3 classes\n",
    "n_samples = 1000\n",
    "classes = ['Positive', 'Negative']\n",
    "data = pd.DataFrame({\n",
    "    'features': np.random.randn(n_samples),\n",
    "    'label': np.random.choice(classes, size=n_samples, p=[0.8, 0.2])\n",
    "})\n",
    "\n",
    "# Define train-test split proportions\n",
    "test_proportions = [0.2, 0.3, 0.4, 0.8]\n",
    "\n",
    "# Function to compute class distribution\n",
    "def get_class_distribution(y, dataset_name):\n",
    "    distribution = y.value_counts(normalize=True).sort_index()\n",
    "    return pd.DataFrame({\n",
    "        'Class': distribution.index,\n",
    "        'Proportion': distribution.values,\n",
    "        'Dataset': dataset_name\n",
    "    })\n",
    "\n",
    "# Collect distributions for visualization\n",
    "distributions = [get_class_distribution(data['label'], 'Original')]\n",
    "\n",
    "# Original dataset distribution\n",
    "\n",
    "# Perform train-test splits and collect distributions\n",
    "for test_size in test_proportions:\n",
    "    # Stratified split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data['features'], data['label'],\n",
    "        train_size=1 - test_size, test_size=test_size,\n",
    "        stratify=data['label'], random_state=42\n",
    "    )\n",
    "\n",
    "    # Training set distribution\n",
    "    distributions.append(get_class_distribution(y_train, f'Train ({int((1 - test_size)*100)}%)'))\n",
    "\n",
    "    # Test set distribution\n",
    "    distributions.append(get_class_distribution(y_test, f'Test ({int(test_size*100)}%)'))\n",
    "\n",
    "# Combine all distributions into a single DataFrame\n",
    "dist_df = pd.concat(distributions, ignore_index=True)\n",
    "\n",
    "# Visualize class distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Class', y='Proportion', hue='Dataset', data=dist_df)\n",
    "plt.title('Class Distributions Across Original, Training, and Test Sets')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xlabel('Class')\n",
    "plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3a035df933e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate the dataset\n",
    "n_samples = 1000\n",
    "classes = ['Positive', 'Negative']\n",
    "data = pd.DataFrame({\n",
    "    'features': np.random.randn(n_samples),\n",
    "    'label': np.random.choice(classes, size=n_samples, p=[0.8, 0.2])\n",
    "})\n",
    "\n",
    "# Define test proportions\n",
    "test_proportions = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "# Prepare figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, test_size in enumerate(test_proportions):\n",
    "    # Split dataset with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data['features'], data['label'], test_size=test_size, stratify=data['label'], random_state=42\n",
    "    )\n",
    "\n",
    "    # Count class distributions\n",
    "    original_counts = data['label'].value_counts().reindex(classes)\n",
    "    train_counts = pd.Series(y_train).value_counts().reindex(classes)\n",
    "    test_counts = original_counts - train_counts # pd.Series(y_test).value_counts().reindex(classes)\n",
    "    test_counts2 = pd.Series(y_test).value_counts().reindex(classes)\n",
    "    print(f\"O: {original_counts}\\nT: {train_counts}\\nt1: {test_counts}\\nt2: {test_counts2}\")\n",
    "    # Create DataFrame for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'Original': original_counts,\n",
    "        'Train': train_counts,\n",
    "        'Test': test_counts\n",
    "    })\n",
    "\n",
    "    # Plot stacked bar chart\n",
    "    df.T.plot(kind='bar', stacked=True, ax=axes[i], color=['#1f77b4', '#ff7f0e'], width=0.8)\n",
    "    axes[i].set_facecolor('white')\n",
    "\n",
    "    axes[i].set_title(f'Train/Test Split: {round((1-test_size)*100)}/{round(test_size*100)}')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend(title='Class', labels=classes)\n",
    "    axes[i].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('class_distribution_stacked.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9b13c5b1da244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate the dataset\n",
    "n_samples = 1000\n",
    "classes = ['Positive', 'Negative']\n",
    "data = pd.DataFrame({\n",
    "    'features': np.random.randn(n_samples),\n",
    "    'label': np.random.choice(classes, size=n_samples, p=[0.8, 0.2])\n",
    "})\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Define test proportions\n",
    "test_proportions = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "# Prepare figure with subplots and white background\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), facecolor='white')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, test_size in enumerate(test_proportions):\n",
    "    # Split dataset with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data['features'], data['label'], test_size=test_size, stratify=data['label'], random_state=42\n",
    "    )\n",
    "\n",
    "    # Count class distributions\n",
    "    original_counts = data['label'].value_counts().reindex(classes)\n",
    "    train_counts = pd.Series(y_train).value_counts().reindex(classes)\n",
    "    test_counts = pd.Series(y_test).value_counts().reindex(classes)\n",
    "\n",
    "    # Create DataFrame for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'Original': original_counts,\n",
    "        'Train': train_counts,\n",
    "        'Test': test_counts\n",
    "    })\n",
    "\n",
    "    # Plot stacked bar chart\n",
    "    ax = axes[i]\n",
    "    bars = df.T.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e'], width=0.8)\n",
    "\n",
    "    # Add counters (text labels) to each segment\n",
    "    for bar in bars.patches:\n",
    "        height = bar.get_height()\n",
    "        width = bar.get_width()\n",
    "        x = bar.get_x()\n",
    "        y = bar.get_y()\n",
    "        if height > 0:  # Only add label if segment exists\n",
    "            label = f'{int(height)}'\n",
    "            ax.text(\n",
    "                x + width / 2, y + height / 2, label,\n",
    "                ha='center', va='center', color='white', fontsize=10, fontweight='bold'\n",
    "            )\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_facecolor('white')\n",
    "    # Set axes background to white\n",
    "    ax.set_title(f'Train/Test Split: {round((1-test_size)*100)}/{round(test_size*100)}')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_xlabel('Dataset')\n",
    "    ax.legend(title='Class', labels=classes)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243b729dff667d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
