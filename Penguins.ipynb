{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276d99f1",
   "metadata": {},
   "source": [
    "- **pandas**: Data manipulation and analysis using DataFrames.\n",
    "- **matplotlib.pyplot**: Create 2D plots and visualizations.\n",
    "- **sklearn.model_selection.train_test_split**: Split data into training and testing sets.\n",
    "- **sklearn.tree.DecisionTreeClassifier**: Decision tree classifier model.\n",
    "- **sklearn.tree.plot_tree**: Visualize the decision tree.\n",
    "- **sklearn.metrics.accuracy_score**: Calculate model accuracy.\n",
    "- **sklearn.metrics.classification_report**: Generate classification report with metrics.\n",
    "- **sklearn.metrics.confusion_matrix**: Compute confusion matrix.\n",
    "- **seaborn**: Create statistical plots with attractive visuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cedd90b",
   "metadata": {},
   "source": [
    "### 1. Preparing and Splitting the Dataset\n",
    "\n",
    "#### 1.1 Data Reading and Preprocessing\n",
    "\n",
    "The dataset is first read into a DataFrame. Categorical variables are encoded using `LabelEncoder` to convert them into numerical form, which is necessary for training machine learning models.\n",
    "\n",
    "##### **Encoding Details**\n",
    "\n",
    "- **Sex**:\n",
    "  - Original values: `\"Female\"` and `\"Male\"`\n",
    "  - Encoded values:\n",
    "    - `0`: Female  \n",
    "    - `1`: Male  \n",
    "  - **Encoding method**: `LabelEncoder`\n",
    "\n",
    "- **Island**:\n",
    "  - Original values: `\"Biscoe\"`, `\"Dream\"`, `\"Torgersen\"`\n",
    "  - Encoded values: `0`, `1`, `2` — based on **alphabetical order**\n",
    "  - **Encoding method**: `LabelEncoder`\n",
    "\n",
    "All other numerical features (`bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g`) are used directly without normalization, as the decision tree algorithm does not require feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -U scikit-learn\n",
    "!python -m pip show scikit-learn\n",
    "!python -c \"import sklearn; sklearn.show_versions()\"\n",
    "!python -m pip install matplotlib\n",
    "!python -m pip install graphviz\n",
    "!python -m pip install seaborn\n",
    "!python -m pip install pandas\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data = pd.read_csv('penguins.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "feature = data[['island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]\n",
    "label = data['species']\n",
    "\n",
    "feature_encoded = feature.copy()\n",
    "\n",
    "feature_encoded['island'] = feature_encoded['island'].map({'Biscoe': 0, 'Dream': 1, 'Torgersen': 2})\n",
    "feature_encoded['sex'] = feature_encoded['sex'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fb2a8",
   "metadata": {},
   "source": [
    "#### 1.2 Visualizing the Original Dataset\n",
    "\n",
    "The Palmer Penguins dataset contains **344 samples** of three species: **Adelie**, **Chinstrap**, and **Gentoo**, along with features like bill size, flipper length, body mass, and sex.\n",
    "\n",
    "Some rows have missing values (e.g., in `sex`, `flipper_length_mm`, `bill_length_mm`), so using `dropna()` reduces the dataset to **333 complete samples**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = label.value_counts().plot(kind='bar')\n",
    "\n",
    "label.value_counts().plot(kind='bar')\n",
    "plt.title(\"Original Dataset Class Distribution\")\n",
    "plt.xlabel(\"Species\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tick_params(axis = 'x', rotation = 45)\n",
    "\n",
    "for p in ax.patches:  \n",
    "    ax.annotate(f'{p.get_height()}',\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  \n",
    "                ha='center', va='center',  \n",
    "                xytext=(0, 9),  \n",
    "                textcoords='offset points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0119039",
   "metadata": {},
   "source": [
    "## 1.3 Split dataset\n",
    "We will split the data according to the ratios 60/40, 40/60, 20/80, 10/90, with a fixed random_state of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d46bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratios = [0.4, 0.6, 0.8, 0.9]\n",
    "random_state = [0]\n",
    "\n",
    "datasets = []\n",
    "\n",
    "\n",
    "for ratio in split_ratios:\n",
    "    for seed in random_state:\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "            feature_encoded, label,\n",
    "            train_size = ratio,\n",
    "            random_state = seed,\n",
    "            shuffle = True,\n",
    "            stratify = label,\n",
    "        )\n",
    "        \n",
    "        datasets.append({\n",
    "            'ratio': ratio,\n",
    "            'seed': seed,\n",
    "            'feature_train': feature_train,\n",
    "            'feature_test': feature_test,\n",
    "            'label_train': label_train,\n",
    "            'label_test': label_test,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487afc3",
   "metadata": {},
   "source": [
    "#### 1.4 Visualizing the Train Dataset and Test Dataset\n",
    "In the chart, the left bars (in blue) represent the training set distribution, while the right bars (in red) show the test set distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f576e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(split_ratios), len(random_state)*2, figsize=(25, 15))\n",
    "\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    row = idx // len(random_state)\n",
    "    col = (idx % len(random_state)) * 2\n",
    "\n",
    "    # Training set plot\n",
    "    axes[row, col].bar(dataset['label_train'].value_counts().index, dataset['label_train'].value_counts().values, color='skyblue')\n",
    "    axes[row, col].set_title(f\"Train {int(dataset['ratio']*100)}/{100-int(dataset['ratio']*100)} Seed {dataset['seed']}\")\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    axes[row, col].set_ylim(0, 140)\n",
    "\n",
    "    # Testing set plot\n",
    "    axes[row, col + 1].bar(dataset['label_test'].value_counts().index, dataset['label_test'].value_counts().values, color='lightcoral')\n",
    "    axes[row, col + 1].set_title(f\"Test {int(dataset['ratio']*100)}/{100-int(dataset['ratio']*100)} Seed {dataset['seed']}\")\n",
    "    axes[row, col + 1].tick_params(axis='x', rotation=45)\n",
    "    axes[row, col + 1].set_ylim(0, 140)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e757f",
   "metadata": {},
   "source": [
    "### 2. Building the Decision Tree Classifiers\n",
    "#### 2.1 Training the Decision Tree\n",
    "We train a **DecisionTreeClassifier** from `sklearn.tree` on each training dataset using the information gain criterion. After training, we visualize the resulting decision tree with **Graphviz**, which provides a clear representation of the model's decision-making process.\n",
    "\n",
    "To install Graphviz, use the following command:\n",
    "```bash\n",
    "pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e018cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "models = []\n",
    "\n",
    "for i, example in enumerate(datasets):\n",
    "    # Train model\n",
    "    model = DecisionTreeClassifier(random_state=example['seed'], criterion='entropy')\n",
    "    model.fit(example['feature_train'], example['label_train'])\n",
    "    models.append(model)\n",
    "\n",
    "    # Export Graphviz data\n",
    "    dot_data = export_graphviz(\n",
    "        model,\n",
    "        out_file=None,\n",
    "        feature_names=feature_encoded.columns,\n",
    "        class_names=[str(c) for c in model.classes_],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True\n",
    "    )\n",
    "\n",
    "    # Create a Graphviz source object\n",
    "    graph = graphviz.Source(dot_data)\n",
    "\n",
    "    # Optional: add custom title to the graph by inserting directly into dot_data\n",
    "    title = f\"Decision Tree {i+1} - Ratio {example['ratio']} Seed {example['seed']}\"\n",
    "    dot_lines = dot_data.split('\\n')\n",
    "    dot_lines.insert(1, f'label=\"{title}\"; labelloc=top; fontsize=20;')  # Add graph label\n",
    "    graph = graphviz.Source('\\n'.join(dot_lines))\n",
    "\n",
    "    # Display graph\n",
    "    display(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e45e7a",
   "metadata": {},
   "source": [
    "#### 2.2 Evaluating the Decision Tree Classifiers\n",
    "After training the decision tree classifiers, it is crucial to assess their performance. We evaluate the models using a variety of metrics, such as accuracy, precision, recall, and F1-score. Additionally, we generate the **confusion matrix** to visualize the classification results and identify areas where the model may be underperforming. These evaluation steps help ensure that the decision tree models are both accurate and reliable for real-world applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de271d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    example = datasets[i]\n",
    "    X_test = example['feature_test']\n",
    "    y_test = example['label_test']\n",
    "    \n",
    "    # Predict and compute accuracy\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n--- Evaluation for Model {i+1} — Ratio {example['ratio']} — Seed {example['seed']} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.title(f\"Confusion Matrix (Model {i+1})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facabcb",
   "metadata": {},
   "source": [
    "#### 2.3 The depth and accuracy of a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb87192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz\n",
    "\n",
    "example = datasets[2]  # datasets[2] is Dataset 3 (80/20)\n",
    "\n",
    "depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "accuracy_results = []\n",
    "\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=example['seed'], criterion='entropy')\n",
    "    model.fit(example['feature_train'], example['label_train'])\n",
    "    y_pred = model.predict(example['feature_test'])\n",
    "\n",
    "    acc = accuracy_score(example['label_test'], y_pred)\n",
    "    accuracy_results.append((depth, acc))\n",
    "\n",
    "    # Export to Graphviz\n",
    "    dot_data = export_graphviz(\n",
    "        model,\n",
    "        out_file=None,\n",
    "        feature_names=feature_encoded.columns,\n",
    "        class_names=[str(c) for c in model.classes_],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True\n",
    "    )\n",
    "\n",
    "    # Add title to the Graphviz tree\n",
    "    title = f\"Decision Tree (max_depth={depth}) - Accuracy: {acc:.2f}\"\n",
    "    dot_lines = dot_data.split('\\n')\n",
    "    dot_lines.insert(1, f'label=\"{title}\"; labelloc=top; fontsize=20;')\n",
    "    graph = graphviz.Source('\\n'.join(dot_lines))\n",
    "    display(graph)\n",
    "\n",
    "# Print accuracy report\n",
    "print(\"\\n=== Accuracy Report ===\")\n",
    "print(\"Max Depth | Accuracy\")\n",
    "for depth, acc in accuracy_results:\n",
    "    print(f\"{str(depth):9} | {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filtered = [(d, a) for d, a in accuracy_results if a is not None]\n",
    "\n",
    "depths = [str(d) for d, _ in filtered]\n",
    "accs = [a for _, a in filtered]\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=150)\n",
    "plt.plot(depths, accs, marker='o')\n",
    "plt.title(\"Accuracy vs Max Depth (Palmer Penguins)\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(top=max(accs) + 0.02)\n",
    "\n",
    "for x, y in zip(depths, accs):\n",
    "    plt.text(x, y + 0.005, f\"{y:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "accuracy_table = pd.DataFrame({'max_depth': depths, 'Accuracy': accs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9f1b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
