{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23b256aed44dd4d",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "[1. Install scikit-learn & required library]($.#1-install-scikit-learn--required-library)<br>\n",
    "[2. Preparing the datasets](#2-preparing-the-datasets)<br>\n",
    "[3. Prepare, Building and Evaluating with the decision tree](#3-prepare-building-and-evaluating-with-the-decision-tree)<br>\n",
    "⠀⠀[3.1 Prepare the splits for the building of the decision tree](#31-prepare-the-splits-for-the-building-of-the-decision-tree)<br>\n",
    "⠀⠀[3.2 Training and evaluate](#32-training-and-evaluate)<br>\n",
    "⠀⠀[3.3 Run all splits](#33-run-all-splits)<br>\n",
    "⠀⠀[3.4 Depth analysis](#34-depth-analysis)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560f090b8e6b00c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "#1",
     "@1asdasds"
    ]
   },
   "source": [
    "# 1. Install scikit-learn & required library\n",
    "This project require numpy, pandas, matplotlib, graphviz, IPython... and scikit-learn be installed. Run the following code to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95fd6b4ea0500a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:03.221795Z",
     "start_time": "2025-04-29T05:11:55.204860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U scikit-learn\n",
    "!python -m pip install matplotlib\n",
    "!python -m pip install graphviz\n",
    "!python -m pip install IPython\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed921fa4808fe546",
   "metadata": {},
   "source": [
    "# 2. Preparing the datasets\n",
    "The following code will download the dataset heart-disease from URL.\n",
    "\n",
    "• Binary class dataset: The [UCI Heart Disease dataset](https://archive.ics.uci.edu/dataset/45/heart+disease) is used for classifying whether a\n",
    "patient has a heart disease or not based on age, blood pressure, cholesterol level, and other\n",
    "medical indicators. This dataset includes 303 samples, with labels indicating presence (1) or\n",
    "absence (0) of heart disease. Experiments with the Cleveland database have concentrated on\n",
    "simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).\n",
    "\n",
    "The dataset will be fetched from URL then split into `feature` and `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4379cebc6a1798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:04.123979Z",
     "start_time": "2025-04-29T05:12:03.221795Z"
    }
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:1319\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1479\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1477\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     14\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     15\u001b[39m \t\t\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m: _dataset.drop(existing_columns, axis=\u001b[32m1\u001b[39m),\n\u001b[32m     16\u001b[39m \t\t\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m: _dataset[existing_columns],\n\u001b[32m     17\u001b[39m \t}\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# fetch dataset from url\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m raw_heart_db = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheart_disease_db_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheart_disease_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m raw_heart_db = raw_heart_db.replace(\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m, np.nan)\n\u001b[32m     22\u001b[39m raw_heart_db = raw_heart_db.dropna()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     req = meth(req)\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    492\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/urllib/request.py:1322\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1319\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1320\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1323\u001b[39m     r = h.getresponse()\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)>"
     ]
    }
   ],
   "source": [
    "heart_disease_db_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "heart_disease_columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "dataset_name = \"Heart Disease\"\n",
    "\n",
    "def split_dataset(_dataset: pd.DataFrame, targets: list):\n",
    "\t\"\"\"\n",
    "\tSplit input dataset into feature and target by input targets\n",
    "\t:return: dict[\"feature\"]\n",
    "\t\"\"\"\n",
    "\texisting_columns = [col for col in targets if col in _dataset.columns]\n",
    "\tmissing_columns = [col for col in targets if col not in _dataset.columns]\n",
    "\tif missing_columns:\n",
    "\t\tprint(\"These columns are not found in the dataset:\", missing_columns)\n",
    "\treturn {\n",
    "\t\t\"feature\": _dataset.drop(existing_columns, axis=1),\n",
    "\t\t\"target\": _dataset[existing_columns],\n",
    "\t}\n",
    "\n",
    "# fetch dataset from url\n",
    "raw_heart_db = pd.read_csv(heart_disease_db_url, names=heart_disease_columns)\n",
    "raw_heart_db = raw_heart_db.replace('?', np.nan)\n",
    "raw_heart_db = raw_heart_db.dropna()\n",
    "raw_heart_db = raw_heart_db.astype(float)\n",
    "raw_heart_db['num'] = raw_heart_db['num'].apply(lambda x: 1 if x > 0 else 0) # labelling the target 'num'\n",
    "\n",
    "dataset = split_dataset(raw_heart_db, targets=['num'])  # adding columns name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd6805985979e1",
   "metadata": {},
   "source": [
    "# 3. Prepare, Building and Evaluating with the decision tree\n",
    "> Required to run the code at [Section #2](#2-preparing-the-datasets) before continue!\n",
    "\n",
    "### 3.1 Prepare the splits for the building of the decision tree\n",
    "This following code splits the dataset into multiple splits with defined ratio.\n",
    "The splits are structured as following `[ratio: float => (feature_train, feature_test, label_train, label_test)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c9a6871d0c062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:04.178042Z",
     "start_time": "2025-04-29T05:12:04.158981Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "split_ratios = [0.6, 0.4, 0.2, 0.1] # train/test 60/40 40/60 80/20 90/10\n",
    "random_seed = None                  # 42 for testing and cultural reference :)\n",
    "class_name = [\"No Decease\", \"Decease\"]\n",
    "\n",
    "def tee_print(message, file):\n",
    "\tprint(message)            # print to console\n",
    "\tprint(message, file=file) # print to log file\n",
    "\n",
    "def snake_case(s: str) -> str:\n",
    "\treturn ''.join('_' if c.isspace() else c.lower() for c in s)\n",
    "\n",
    "snake_cased_dataset_name = snake_case(dataset_name)\n",
    "os.makedirs(f\"output/depth/{snake_cased_dataset_name}\", exist_ok=True)\n",
    "os.makedirs(f\"output/splits/{snake_cased_dataset_name}\", exist_ok=True)\n",
    "\n",
    "def prepare_dataset(features, labels, test_size, seed=None):\n",
    "\t\"\"\"\n",
    "\t:param features: input features\n",
    "\t:param labels: input labels\n",
    "\t:param test_size: Test size ratio (test/(train+test))\n",
    "\t:param seed: seed used for random, default=None for random seed\n",
    "\t:return: feature_train, feature_test, label_train, label_test\n",
    "\t\"\"\"\n",
    "\treturn train_test_split(features, labels, test_size=test_size, stratify=labels, random_state=seed, shuffle=True)\n",
    "\n",
    "def prepare_all_splits(features, labels, seed=None):\n",
    "    splits = {}\n",
    "    for split_ratio in split_ratios:\n",
    "        splits[split_ratio] = prepare_dataset(features, labels, test_size=split_ratio, seed=seed)\n",
    "    return splits\n",
    "\n",
    "dataset_splits = prepare_all_splits(dataset['feature'], dataset['target'], seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5999286da085aa4",
   "metadata": {},
   "source": [
    "#### 3.1.a Visualize the class distributions in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8b3eb8bbf92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:05.014406Z",
     "start_time": "2025-04-29T05:12:04.214375Z"
    }
   },
   "outputs": [],
   "source": [
    "def visual_class_distribution():\n",
    "\t# Prepare figure with subplots and white background\n",
    "\tfig, axes = plt.subplots(2, 2, figsize=(12, 8), facecolor='white')\n",
    "\taxes = axes.flatten()\n",
    "\n",
    "\tfor i, test_size in enumerate(split_ratios):\n",
    "\t\t_feature_train, _feature_test, _label_train, _label_test = dataset_splits[test_size]\n",
    "\n",
    "\t\toriginal_counts = dataset['target']['num'].value_counts() #.reindex(class_name)\n",
    "\t\ttrain_counts = pd.Series(_label_train['num']).value_counts() #.reindex(class_name)\n",
    "\t\ttest_counts = pd.Series(_label_test['num']).value_counts() #.reindex(class_name)\n",
    "\t\tdf = pd.DataFrame({\n",
    "\t\t    'Original': original_counts,\n",
    "\t        'Train': train_counts,\n",
    "\t        'Test': test_counts\n",
    "\t\t})\n",
    "\n",
    "\t    # plot stacked bar chart\n",
    "\t\tax = axes[i]\n",
    "\t\tbars = df.T.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e'], width=0.8)\n",
    "\n",
    "\t\t# add counters (text labels) to each segment\n",
    "\t\tfor bar in bars.patches:\n",
    "\t\t    height = bar.get_height()\n",
    "\t\t    width = bar.get_width()\n",
    "\t\t    x = bar.get_x()\n",
    "\t\t    y = bar.get_y()\n",
    "\t\t    if height > 0:  # Only add label if segment exists\n",
    "\t\t        label = f'{int(height)}'\n",
    "\t\t        ax.text(\n",
    "\t\t            x + width / 2, y + height / 2, label,\n",
    "\t\t            ha='center', va='center', color='white', fontsize=10, fontweight='bold'\n",
    "\t\t        )\n",
    "\t\t# Customize plot\n",
    "\t\tax.set_facecolor('white')\n",
    "\t\t# Set axes background to white\n",
    "\t\tax.set_title(f'Train/Test Split: {round((1-test_size)*100)}/{round(test_size*100)}')\n",
    "\t\tax.set_ylabel('Count')\n",
    "\t\tax.set_xlabel('Dataset')\n",
    "\t\tax.legend(title='Class', labels=class_name)\n",
    "\t\tax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"output/splits/{snake_cased_dataset_name}/split_distribution_{snake_cased_dataset_name}.png\")\n",
    "\tplt.show()\n",
    "visual_class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e78548f191ed8",
   "metadata": {},
   "source": [
    "### 3.2 Training and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8060411673ddc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:05.061796Z",
     "start_time": "2025-04-29T05:12:05.056351Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def build_id3_tree(feature_train, label_train, max_depth=None) -> DecisionTreeClassifier:\n",
    "\tdtc = DecisionTreeClassifier(criterion='entropy', random_state=random_seed, max_depth=max_depth)\n",
    "\tdtc.fit(feature_train, label_train) # train\n",
    "\treturn dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e4ae13379bb93",
   "metadata": {},
   "source": [
    "### 3.3 Run all splits\n",
    "> Required to run the code at [Section #3.2](#32-training-and-evaluate) before continue!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266aa6c0152f28a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:06.651872Z",
     "start_time": "2025-04-29T05:12:05.119510Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree, export_graphviz\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import graphviz\n",
    "\n",
    "def run_all_splits():\n",
    "\twith open(f\"output/splits/{snake_cased_dataset_name}/log.txt\", \"w\") as log_file:\n",
    "\t\tfor test_size in split_ratios:\n",
    "\t\t\t_feature_train, _feature_test, _label_train, _label_test = dataset_splits[test_size]\n",
    "\t\t\tdtc = build_id3_tree(_feature_train, _label_train)\n",
    "\t\t\t# export decision tree to DOT format\n",
    "\t\t\t_dot_data = export_graphviz(dtc, feature_names=_feature_train.columns, class_names=class_name, filled=True, rounded=True, special_characters=True)\n",
    "\t\t\t_graph = graphviz.Source(_dot_data, format=\"svg\")\n",
    "\t\t\ttee_print(f\"=== {dataset_name} Train/Test {100 - round(test_size * 100)}/{round(test_size * 100)} ===\", file=log_file)\n",
    "\t\t\tdisplay(_graph)\n",
    "\n",
    "\t\t\t_output_file = f\"output/splits/{snake_cased_dataset_name}/id3_{snake_cased_dataset_name}_{100 - round(test_size * 100)}_{round(test_size * 100)}\"\n",
    "\t\t\t_graph.render(_output_file, cleanup=True, directory=\".\")\n",
    "\t\t\ttee_print(f\"Saved decision tree visualization: {_output_file}.svg\", file=log_file)\n",
    "\t\t\t_label_predict = dtc.predict(_feature_test) # predict the label of feature_test based on the tree\n",
    "\t\t\ttee_print(classification_report(_label_test, _label_predict, target_names=[\"No Decease\", \"Decease\"]), file=log_file)\n",
    "\n",
    "\t\t\tcm = confusion_matrix(_label_test, _label_predict)\n",
    "\t\t\tdisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_name)\n",
    "\t\t\tfig, ax = plt.subplots(figsize=(8, 6))\n",
    "\t\t\tdisp.plot(ax=ax, cmap='Blues')\n",
    "\t\t\tplt.title(f\"Confusion Matrix (Depth=None, {100 - round(test_size * 100)}/{round(test_size * 100)})\")\n",
    "\t\t\tplt.yticks(rotation=90)\n",
    "\t\t\tplt.grid(False)\n",
    "\t\t\tplt.savefig(f\"output/splits/{snake_cased_dataset_name}/confusion_matrix_{snake_cased_dataset_name}_{100 - round(test_size * 100)}_{round(test_size * 100)}.png\", dpi=150)\n",
    "\t\t\tplt.show()\n",
    "run_all_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaccac54a1b2dfe",
   "metadata": {},
   "source": [
    "### 3.4 Depth analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d63121840fc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:07.928133Z",
     "start_time": "2025-04-29T05:12:06.700138Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "accuracies = []\n",
    "\n",
    "with open(\"output/depth/heart_disease/log.txt\", \"w\") as log_file:\n",
    "\tfeature_train, feature_test, label_train, label_test = dataset_splits[0.2]\n",
    "\tfor d in depths:\n",
    "\t\t# train decision tree with specified max_depth\n",
    "\t\tdtc = build_id3_tree(feature_train, label_train, max_depth=d)\n",
    "\t\tresult_depth = dtc.get_depth()\n",
    "\t\tlabel_predict = dtc.predict(feature_test)\n",
    "\t\tacc = accuracy_score(label_test, label_predict)\n",
    "\t\taccuracies.append(acc)\n",
    "\n",
    "\t\ttee_print(f\"Max Depth: {d} - Actual Depth: {result_depth} - Accuracy: {acc:.4f}\", file=log_file)\n",
    "\t\tsys.stdout.flush()\n",
    "\n",
    "\t\t# export decision tree to DOT format\n",
    "\t\t_dot_data = export_graphviz(dtc, feature_names=feature_train.columns, class_names=class_name, filled=True, rounded=True, special_characters=True)\n",
    "\t\t_graph = graphviz.Source(_dot_data, format=\"svg\")\n",
    "\n",
    "\t\t_output_file = f\"output/depth/{snake_cased_dataset_name}/id3_{snake_cased_dataset_name}_80_20_depth_{d if d is not None else \"none\"}\"\n",
    "\t\t_graph.render(_output_file, cleanup=True, directory=\".\")\n",
    "\t\tdisplay(_graph)\n",
    "\t\ttee_print(f\"Saved decision tree visualization: {_output_file}.svg\", file=log_file)\n",
    "\t\ttee_print(f\"-====================================================-\\n\", file=log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7b14a6de8b4d2",
   "metadata": {},
   "source": [
    "#### 3.4.a Charts showing correlation between max depth and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e910e40c208c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T05:12:08.214483Z",
     "start_time": "2025-04-29T05:12:07.975933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot accuracies\n",
    "plt.figure(figsize=(10, 6), dpi=150)\n",
    "plt.plot([str(d) for d in depths], accuracies, marker='o')\n",
    "plt.title(f\"Accuracy vs Max Depth ({dataset_name})\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.ylim(top=max(accuracies) + 0.02)  # add a bit of headroom\n",
    "# add value labels above each point\n",
    "for x, y in zip([str(d) for d in depths], accuracies):\n",
    "\tplt.text(x, y + 0.005, f\"{y:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "plt.grid()\n",
    "plt.savefig(f\"output/depth/{snake_cased_dataset_name}/accuracy_{snake_cased_dataset_name}.png\", dpi=150)\n",
    "plt.show()\n",
    "accuracy_table = pd.DataFrame({'max_depth': [str(d) for d in depths], 'Accuracy': accuracies})\n",
    "with open(\"output/depth/heart_disease/log.txt\", \"a\") as log_file:\n",
    "\ttee_print(accuracy_table, file=log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
